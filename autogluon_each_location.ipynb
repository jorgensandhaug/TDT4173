{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Processing location A...\n",
      "Shape of X_train_observed before dropping in-between hour rows:  (118669, 45)\n",
      "HEIHEI: X_train_observed gaps in dates:  0\n",
      "HEIHEI: X_train_observed first gap in dates:  DatetimeIndex([], dtype='datetime64[us]', name='ds', freq=None)\n",
      "HEIHEI: X_train_observed list of size (in days) of each gap:  []\n",
      "HEIHEI: X_train_observed gaps in dates after filling missing dates:  0\n",
      "Shape of X_train_observed after dropping in-between hour rows:  (29668, 45)\n",
      "Shape of X_train_estimated before dropping in-between hour rows:  (17576, 46)\n",
      "HEIHEI: X_train_estimated gaps in dates:  1\n",
      "HEIHEI: X_train_estimated first gap in dates:  DatetimeIndex(['2023-01-27'], dtype='datetime64[us]', name='ds', freq=None)\n",
      "HEIHEI: X_train_estimated list of size (in days) of each gap:  [1.01041667]\n",
      "HEIHEI: X_train_estimated gaps in dates after filling missing dates:  0\n",
      "Shape of X_train_estimated after dropping in-between hour rows:  (4418, 46)\n",
      "Shape of X_test before dropping in-between hour rows:  (2880, 46)\n",
      "HEIHEI: X_test gaps in dates:  17\n",
      "HEIHEI: X_test first gap in dates:  DatetimeIndex(['2023-05-06'], dtype='datetime64[us]', name='ds', freq=None)\n",
      "HEIHEI: X_test list of size (in days) of each gap:  [4.01041667 7.01041667 3.01041667 1.01041667 1.01041667 1.01041667\n",
      " 1.01041667 1.01041667 1.01041667 2.01041667 1.01041667 1.01041667\n",
      " 3.01041667 2.01041667 3.01041667 1.01041667 1.01041667]\n",
      "HEIHEI: X_test gaps in dates after filling missing dates:  0\n",
      "Shape of X_test after dropping in-between hour rows:  (1536, 46)\n",
      "X_train_observed shape: (29668, 46)\n",
      "X_train_estimated shape: (4418, 46)\n",
      "X_test shape: (1536, 46)\n",
      "y_train shape: (34085, 1)\n",
      "y_train columns:  Index(['y'], dtype='object')\n",
      "Shape of y_train before filling missing dates:  (34085, 1)\n",
      "Shape of y_train after filling missing dates:  (34274, 1)\n",
      "LOOK: Number of gaps in X_train_observed plus number of gaps in X_train_estimated before:  0\n",
      "LOOK: Number of gaps in X_train_observed plus number of gaps in X_train_estimated after:  1\n",
      "LOOK: list of size (in days) of each gap:  [7.875]\n",
      "if the number is bigger after than before that means there is a gap in time between the observed and estimated training sets\n",
      "X_train dates info:  2019-06-02 22:00:00 2023-04-30 23:00:00 1428 days 01:00:00\n",
      "X_test dates info:  2023-05-01 00:00:00 2023-07-03 23:00:00 63 days 23:00:00\n",
      "y_train dates info:  2019-06-02 22:00:00 2023-04-30 23:00:00 1428 days 01:00:00\n",
      "X_train gaps in dates:  1\n",
      "X_test gaps in dates:  0\n",
      "y_train gaps in dates:  0\n",
      "X_train gaps in dates after filling missing dates:  0\n",
      "X_test gaps in dates after filling missing dates:  0\n",
      "Number of missing values in X_train:  53521\n",
      "Number of missing values in X_test:  38573\n",
      "Number of missing values in y_train:  189\n",
      "Number of missing values in X_train after merging with y_train:  53521\n",
      "Final shape of X_train for location A:  (34274, 48)\n",
      "Final shape of X_test for location A:  (1536, 47)\n",
      "\n",
      "\n",
      "\n",
      "Processing location B...\n",
      "Shape of X_train_observed before dropping in-between hour rows:  (116929, 45)\n",
      "HEIHEI: X_train_observed gaps in dates:  0\n",
      "HEIHEI: X_train_observed first gap in dates:  DatetimeIndex([], dtype='datetime64[us]', name='ds', freq=None)\n",
      "HEIHEI: X_train_observed list of size (in days) of each gap:  []\n",
      "HEIHEI: X_train_observed gaps in dates after filling missing dates:  0\n",
      "Shape of X_train_observed after dropping in-between hour rows:  (29233, 45)\n",
      "Shape of X_train_estimated before dropping in-between hour rows:  (17576, 46)\n",
      "HEIHEI: X_train_estimated gaps in dates:  1\n",
      "HEIHEI: X_train_estimated first gap in dates:  DatetimeIndex(['2023-01-27'], dtype='datetime64[us]', name='ds', freq=None)\n",
      "HEIHEI: X_train_estimated list of size (in days) of each gap:  [1.01041667]\n",
      "HEIHEI: X_train_estimated gaps in dates after filling missing dates:  0\n",
      "Shape of X_train_estimated after dropping in-between hour rows:  (4418, 46)\n",
      "Shape of X_test before dropping in-between hour rows:  (2880, 46)\n",
      "HEIHEI: X_test gaps in dates:  17\n",
      "HEIHEI: X_test first gap in dates:  DatetimeIndex(['2023-05-06'], dtype='datetime64[us]', name='ds', freq=None)\n",
      "HEIHEI: X_test list of size (in days) of each gap:  [4.01041667 7.01041667 3.01041667 1.01041667 1.01041667 1.01041667\n",
      " 1.01041667 1.01041667 1.01041667 2.01041667 1.01041667 1.01041667\n",
      " 3.01041667 2.01041667 3.01041667 1.01041667 1.01041667]\n",
      "HEIHEI: X_test gaps in dates after filling missing dates:  0\n",
      "Shape of X_test after dropping in-between hour rows:  (1536, 46)\n",
      "X_train_observed shape: (29233, 46)\n",
      "X_train_estimated shape: (4418, 46)\n",
      "X_test shape: (1536, 46)\n",
      "y_train shape: (32848, 1)\n",
      "y_train columns:  Index(['y'], dtype='object')\n",
      "Shape of y_train before filling missing dates:  (32848, 1)\n",
      "Shape of y_train after filling missing dates:  (37945, 1)\n",
      "LOOK: Number of gaps in X_train_observed plus number of gaps in X_train_estimated before:  0\n",
      "LOOK: Number of gaps in X_train_observed plus number of gaps in X_train_estimated after:  1\n",
      "LOOK: list of size (in days) of each gap:  [178.91666667]\n",
      "if the number is bigger after than before that means there is a gap in time between the observed and estimated training sets\n",
      "X_train dates info:  2019-01-01 00:00:00 2023-04-30 23:00:00 1580 days 23:00:00\n",
      "X_test dates info:  2023-05-01 00:00:00 2023-07-03 23:00:00 63 days 23:00:00\n",
      "y_train dates info:  2018-12-31 23:00:00 2023-04-30 23:00:00 1581 days 00:00:00\n",
      "X_train gaps in dates:  1\n",
      "X_test gaps in dates:  0\n",
      "y_train gaps in dates:  0\n",
      "X_train gaps in dates after filling missing dates:  0\n",
      "X_test gaps in dates after filling missing dates:  0\n",
      "Number of missing values in X_train:  239726\n",
      "Number of missing values in X_test:  38553\n",
      "Number of missing values in y_train:  5101\n",
      "Number of missing values in X_train after merging with y_train:  239772\n",
      "Final shape of X_train for location B:  (37945, 48)\n",
      "Final shape of X_test for location B:  (1536, 47)\n",
      "\n",
      "\n",
      "\n",
      "Processing location C...\n",
      "Shape of X_train_observed before dropping in-between hour rows:  (116825, 45)\n",
      "HEIHEI: X_train_observed gaps in dates:  0\n",
      "HEIHEI: X_train_observed first gap in dates:  DatetimeIndex([], dtype='datetime64[us]', name='ds', freq=None)\n",
      "HEIHEI: X_train_observed list of size (in days) of each gap:  []\n",
      "HEIHEI: X_train_observed gaps in dates after filling missing dates:  0\n",
      "Shape of X_train_observed after dropping in-between hour rows:  (29207, 45)\n",
      "Shape of X_train_estimated before dropping in-between hour rows:  (17576, 46)\n",
      "HEIHEI: X_train_estimated gaps in dates:  1\n",
      "HEIHEI: X_train_estimated first gap in dates:  DatetimeIndex(['2023-01-27'], dtype='datetime64[us]', name='ds', freq=None)\n",
      "HEIHEI: X_train_estimated list of size (in days) of each gap:  [1.01041667]\n",
      "HEIHEI: X_train_estimated gaps in dates after filling missing dates:  0\n",
      "Shape of X_train_estimated after dropping in-between hour rows:  (4418, 46)\n",
      "Shape of X_test before dropping in-between hour rows:  (2880, 46)\n",
      "HEIHEI: X_test gaps in dates:  17\n",
      "HEIHEI: X_test first gap in dates:  DatetimeIndex(['2023-05-06'], dtype='datetime64[us]', name='ds', freq=None)\n",
      "HEIHEI: X_test list of size (in days) of each gap:  [4.01041667 7.01041667 3.01041667 1.01041667 1.01041667 1.01041667\n",
      " 1.01041667 1.01041667 1.01041667 2.01041667 1.01041667 1.01041667\n",
      " 3.01041667 2.01041667 3.01041667 1.01041667 1.01041667]\n",
      "HEIHEI: X_test gaps in dates after filling missing dates:  0\n",
      "Shape of X_test after dropping in-between hour rows:  (1536, 46)\n",
      "X_train_observed shape: (29207, 46)\n",
      "X_train_estimated shape: (4418, 46)\n",
      "X_test shape: (1536, 46)\n",
      "y_train shape: (32155, 1)\n",
      "y_train columns:  Index(['y'], dtype='object')\n",
      "Shape of y_train before filling missing dates:  (32155, 1)\n",
      "Shape of y_train after filling missing dates:  (37945, 1)\n",
      "LOOK: Number of gaps in X_train_observed plus number of gaps in X_train_estimated before:  0\n",
      "LOOK: Number of gaps in X_train_observed plus number of gaps in X_train_estimated after:  1\n",
      "LOOK: list of size (in days) of each gap:  [180.]\n",
      "if the number is bigger after than before that means there is a gap in time between the observed and estimated training sets\n",
      "X_train dates info:  2019-01-01 00:00:00 2023-04-30 23:00:00 1580 days 23:00:00\n",
      "X_test dates info:  2023-05-01 00:00:00 2023-07-03 23:00:00 63 days 23:00:00\n",
      "y_train dates info:  2018-12-31 23:00:00 2023-04-30 23:00:00 1581 days 00:00:00\n",
      "X_train gaps in dates:  1\n",
      "X_test gaps in dates:  0\n",
      "y_train gaps in dates:  0\n",
      "X_train gaps in dates after filling missing dates:  0\n",
      "X_test gaps in dates after filling missing dates:  0\n",
      "Number of missing values in X_train:  240647\n",
      "Number of missing values in X_test:  38610\n",
      "Number of missing values in y_train:  11850\n",
      "Number of missing values in X_train after merging with y_train:  240693\n",
      "Final shape of X_train for location C:  (37945, 48)\n",
      "Final shape of X_test for location C:  (1536, 47)\n",
      "Final shape of X_train:  (110164, 48)\n",
      "Final shape of X_test:  (4608, 47)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def fix_datetime(X, name):\n",
    "    \"\"\"\n",
    "    Function to fix and standardize datetime in the given DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: DataFrame to be modified.\n",
    "    - name: String representing the name of the DataFrame, used for logging.\n",
    "    \n",
    "    Returns:\n",
    "    - Modified DataFrame with standardized datetime.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert 'date_forecast' to datetime format and replace original column with 'ds'\n",
    "    X['ds'] = pd.to_datetime(X['date_forecast'])\n",
    "    X.drop(columns=['date_forecast'], inplace=True, errors='ignore')\n",
    "\n",
    "    # Sort DataFrame by the new datetime column ('ds') and set it as the index\n",
    "    X.sort_values(by='ds', inplace=True)\n",
    "    X.set_index('ds', inplace=True)\n",
    "\n",
    "    # Log the shape of the DataFrame before dropping rows with in-between minutes\n",
    "    print(f\"Shape of {name} before dropping in-between hour rows: \", X.shape)\n",
    "\n",
    "    # Identify and log gaps in the date sequence\n",
    "    print(f\"HEIHEI: {name} gaps in dates: \", X.index.to_series().diff().dt.total_seconds().gt(60*15).sum())\n",
    "    print(f\"HEIHEI: {name} first gap in dates: \", X[X.index.to_series().diff().dt.total_seconds().gt(60*15)==True].index[:1])\n",
    "\n",
    "    # Calculate and log the size of each gap in the date sequence\n",
    "    temp = X.index.to_series().diff().dt.total_seconds()\n",
    "    if temp.shape[0] > 0:\n",
    "        print(f\"HEIHEI: {name} list of size (in days) of each gap: \", temp[temp.gt(60*15)].values / (60*60*24))\n",
    "    \n",
    "    # temporarily transform into darts time series to fill missing dates\n",
    "    # get date_calc if date_calc is column in X\n",
    "    temp_calc = None\n",
    "    if \"date_calc\" in X.columns:\n",
    "        temp_calc = X[\"date_calc\"]\n",
    "        X.drop(columns=['date_calc'], inplace=True)\n",
    "    X = TimeSeries.from_dataframe(df=X, freq=\"15T\", fill_missing_dates=True, fillna_value=None).pd_dataframe()\n",
    "    if temp_calc is not None:\n",
    "        X[\"date_calc\"] = temp_calc\n",
    "\n",
    "    print(f\"HEIHEI: {name} gaps in dates after filling missing dates: \", X.index.to_series().diff().dt.total_seconds().gt(60*15).sum())\n",
    "\n",
    "\n",
    "    # Drop rows where the minute part of the time is not 0\n",
    "    X = X[X.index.minute == 0]\n",
    "\n",
    "    # Log the shape of the DataFrame after dropping rows with in-between minutes\n",
    "    print(f\"Shape of {name} after dropping in-between hour rows: \", X.shape)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_datetime(X_train_observed, X_train_estimated, X_test, y_train):\n",
    "    X_train_observed = fix_datetime(X_train_observed, \"X_train_observed\")\n",
    "    X_train_estimated = fix_datetime(X_train_estimated, \"X_train_estimated\")\n",
    "    X_test = fix_datetime(X_test, \"X_test\")\n",
    "\n",
    "\n",
    "    X_train_observed[\"estimated_diff_hours\"] = 0\n",
    "    X_train_estimated[\"estimated_diff_hours\"] = (X_train_estimated.index - pd.to_datetime(X_train_estimated[\"date_calc\"])).dt.total_seconds() / 3600.0\n",
    "    X_test[\"estimated_diff_hours\"] = (X_test.index - pd.to_datetime(X_test[\"date_calc\"])).dt.total_seconds() / 3600.0\n",
    "\n",
    "    X_train_estimated.drop(columns=['date_calc'], inplace=True)\n",
    "    X_test.drop(columns=['date_calc'], inplace=True)\n",
    "\n",
    "    y_train['ds'] = pd.to_datetime(y_train['time'])\n",
    "    y_train.drop(columns=['time'], inplace=True)\n",
    "    y_train.sort_values(by='ds', inplace=True)\n",
    "    y_train.set_index('ds', inplace=True)\n",
    "\n",
    "    return X_train_observed, X_train_estimated, X_test, y_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# location_map = {\n",
    "#     \"A\": 0,\n",
    "#     \"B\": 1,\n",
    "#     \"C\": 2\n",
    "# }\n",
    "\n",
    "\n",
    "def preprocess_data(X_train_observed, X_train_estimated, X_test, y_train, location):\n",
    "    # convert to datetime\n",
    "    X_train_observed, X_train_estimated, X_test, y_train = convert_to_datetime(X_train_observed, X_train_estimated, X_test, y_train)\n",
    "\n",
    "\n",
    "    # # cast all columns to float64\n",
    "    # X_train = X_train.astype('float64')\n",
    "    # X_test = X_test.astype('float64')\n",
    "\n",
    "\n",
    "    print(f\"X_train_observed shape: {X_train_observed.shape}\")\n",
    "    print(f\"X_train_estimated shape: {X_train_estimated.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "    y_train[\"y\"] = y_train[\"pv_measurement\"].astype('float64')\n",
    "    y_train.drop(columns=['pv_measurement'], inplace=True)\n",
    "    print(\"y_train columns: \", y_train.columns)\n",
    "\n",
    "    # temporarily transform into darts time series to fill missing dates\n",
    "    print(\"Shape of y_train before filling missing dates: \", y_train.shape)\n",
    "    y_train = TimeSeries.from_dataframe(df=y_train, freq=\"H\", fill_missing_dates=True, fillna_value=None).pd_dataframe()\n",
    "    print(\"Shape of y_train after filling missing dates: \", y_train.shape)\n",
    "\n",
    "\n",
    "    # number of gaps in X_train_observed + X_train_estimated before\n",
    "    print(f\"LOOK: Number of gaps in X_train_observed plus number of gaps in X_train_estimated before: \", X_train_observed.index.to_series().diff().dt.total_seconds().gt(3600).sum() + X_train_estimated.index.to_series().diff().dt.total_seconds().gt(3600).sum())\n",
    "    X_train = pd.concat([X_train_observed, X_train_estimated])\n",
    "    print(f\"LOOK: Number of gaps in X_train_observed plus number of gaps in X_train_estimated after: \", X_train.index.to_series().diff().dt.total_seconds().gt(3600).sum())\n",
    "    # print size of gaps in X_train\n",
    "    temp = X_train.index.to_series().diff().dt.total_seconds()\n",
    "    if temp.shape[0] > 0:\n",
    "        print(\"LOOK: list of size (in days) of each gap: \", temp[temp.gt(3600)].values / (60*60*24))\n",
    "    print(\"if the number is bigger after than before that means there is a gap in time between the observed and estimated training sets\")\n",
    "\n",
    "    # print info on dates in X_train, and if there are any missing dates\n",
    "    print(\"X_train dates info: \", X_train.index.min(), X_train.index.max(), X_train.index.max() - X_train.index.min())\n",
    "    print(\"X_test dates info: \", X_test.index.min(), X_test.index.max(), X_test.index.max() - X_test.index.min())\n",
    "    print(\"y_train dates info: \", y_train.index.min(), y_train.index.max(), y_train.index.max() - y_train.index.min())\n",
    "\n",
    "    # any gaps in dates?\n",
    "    print(\"X_train gaps in dates: \", X_train.index.to_series().diff().dt.total_seconds().gt(3600).sum())\n",
    "    print(\"X_test gaps in dates: \", X_test.index.to_series().diff().dt.total_seconds().gt(3600).sum())\n",
    "    print(\"y_train gaps in dates: \", y_train.index.to_series().diff().dt.total_seconds().gt(3600).sum())\n",
    "\n",
    "    # temporarily transform into darts time series to fill missing dates\n",
    "    X_train = TimeSeries.from_dataframe(df=X_train, freq=\"H\", fill_missing_dates=True, fillna_value=None).pd_dataframe()\n",
    "    X_test = TimeSeries.from_dataframe(df=X_test, freq=\"H\", fill_missing_dates=True, fillna_value=None).pd_dataframe()\n",
    "    print(\"X_train gaps in dates after filling missing dates: \", X_train.index.to_series().diff().dt.total_seconds().gt(3600).sum())\n",
    "    print(\"X_test gaps in dates after filling missing dates: \", X_test.index.to_series().diff().dt.total_seconds().gt(3600).sum())\n",
    "\n",
    "    \n",
    "\n",
    "    # clip all y values to 0 if negative\n",
    "    y_train[\"y\"] = y_train[\"y\"].clip(lower=0)\n",
    "    \n",
    "    # print Number of missing values in X train\n",
    "    print(\"Number of missing values in X_train: \", X_train.isnull().sum().sum())\n",
    "    print(\"Number of missing values in X_test: \", X_test.isnull().sum().sum())\n",
    "    # y_train missing values\n",
    "    print(\"Number of missing values in y_train: \", y_train.isnull().sum().sum())\n",
    "    X_train = pd.merge(X_train, y_train, how=\"outer\", left_index=True, right_index=True)\n",
    "    print(\"Number of missing values in X_train after merging with y_train: \", X_train.drop(columns=['y']).isnull().sum().sum())\n",
    "\n",
    "\n",
    "\n",
    "    X_train[\"location\"] = location\n",
    "    X_test[\"location\"] = location\n",
    "    \n",
    "    return X_train, X_test\n",
    "    \n",
    "\n",
    "\n",
    "# Define locations\n",
    "locations = ['A', 'B', 'C']\n",
    "\n",
    "X_trains = []\n",
    "X_tests = []\n",
    "y_trains = []\n",
    "# Loop through locations\n",
    "for loc in locations:\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Processing location {loc}...\")\n",
    "    # Read target training data\n",
    "    y_train = pd.read_parquet(f'{loc}/train_targets.parquet')\n",
    "    \n",
    "    # Read estimated training data and add location feature\n",
    "    X_train_estimated = pd.read_parquet(f'{loc}/X_train_estimated.parquet')\n",
    "    \n",
    "    # Read observed training data and add location feature\n",
    "    X_train_observed= pd.read_parquet(f'{loc}/X_train_observed.parquet')\n",
    "\n",
    "    # Read estimated test data and add location feature\n",
    "    X_test_estimated = pd.read_parquet(f'{loc}/X_test_estimated.parquet')\n",
    "    \n",
    "    # Concatenate observed and estimated datasets for each location\n",
    "    #X_train = pd.concat([X_train_estimated, X_train_observed])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train, X_test = preprocess_data(X_train_observed, X_train_estimated, X_test_estimated, y_train, loc)\n",
    "\n",
    "    print(f\"Final shape of X_train for location {loc}: \", X_train.shape)\n",
    "    print(f\"Final shape of X_test for location {loc}: \", X_test.shape)\n",
    "\n",
    "    # print(y_train.head(), y_train.shape)\n",
    "    # print(X_train.head(), X_train.shape)\n",
    "    # print(X_train.head(), X_train.shape)\n",
    "    # print(type(X_train['y']))\n",
    "\n",
    "    # Save data to csv\n",
    "    X_train.to_csv(f'{loc}/X_train.csv', index=True)\n",
    "    X_test.to_csv(f'{loc}/X_test.csv', index=True)\n",
    "\n",
    "\n",
    "    X_trains.append(X_train)\n",
    "    X_tests.append(X_test)\n",
    "\n",
    "# Concatenate all data and save to csv\n",
    "X_train = pd.concat(X_trains)\n",
    "X_test = pd.concat(X_tests)\n",
    "\n",
    "print(f\"Final shape of X_train: \", X_train.shape)\n",
    "print(f\"Final shape of X_test: \", X_test.shape)\n",
    "\n",
    "X_train.to_csv('X_train_raw.csv', index=True)\n",
    "X_test.to_csv('X_test_raw.csv', index=True)\n",
    "\n",
    "\n",
    "# save where nan y values are dropped\n",
    "X_train_non_nan = X_train.dropna(subset=['y'])\n",
    "X_train_non_nan.to_csv('X_train_non_nan.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = X_train_non_nan.copy()\n",
    "test_df = X_test.copy()\n",
    "\n",
    "\n",
    "# add sin and cos of sun_elevation:d and sun_azimuth:d\n",
    "df['sin_sun_elevation'] = np.sin(np.deg2rad(df['sun_elevation:d']))\n",
    "\n",
    "test_df['sin_sun_elevation'] = np.sin(np.deg2rad(test_df['sun_elevation:d']))\n",
    "\n",
    "# add global_rad_1h:J = diffuse_rad_1h:J + direct_rad_1h:J\n",
    "df['global_rad_1h:J'] = df['diffuse_rad_1h:J'] + df['direct_rad_1h:J']\n",
    "test_df['global_rad_1h:J'] = test_df['diffuse_rad_1h:J'] + test_df['direct_rad_1h:J']\n",
    "\n",
    "# dew_or_rime:idx, Change this to one variable for is_dew and one variable for is_rime (dew:1, rime:-1)\n",
    "df['is_dew'] = df['dew_or_rime:idx'].apply(lambda x: 1 if x == 1 else 0)\n",
    "df['is_rime'] = df['dew_or_rime:idx'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "test_df['is_dew'] = test_df['dew_or_rime:idx'].apply(lambda x: 1 if x == 1 else 0)\n",
    "test_df['is_rime'] = test_df['dew_or_rime:idx'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "\n",
    "EXOGENOUS = [\n",
    "    'estimated_diff_hours',\n",
    "    \"absolute_humidity_2m:gm3\",\n",
    "    \"air_density_2m:kgm3\",\n",
    "    \"dew_point_2m:K\",\n",
    "    \"diffuse_rad_1h:J\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"fresh_snow_1h:cm\",\n",
    "    \"snow_depth:cm\",\n",
    "    \"sun_elevation:d\",\n",
    "    \"sun_azimuth:d\",\n",
    "    \"t_1000hPa:K\",\n",
    "    \"visibility:m\",\n",
    "    \"wind_speed_10m:ms\",\n",
    "    \"is_dew\",\n",
    "    \"is_rime\",\n",
    "    \"sin_sun_elevation\",\n",
    "    \"global_rad_1h:J\",\n",
    "    ]\n",
    "#additional_features_for_testing = \n",
    "\n",
    "df = df[EXOGENOUS + [\"y\", \"location\"]]\n",
    "test_df = test_df[EXOGENOUS+ [\"location\"]]\n",
    "\n",
    "# save to X_train_feature_engineered.csv\n",
    "df.to_csv('X_train_feature_engineered.csv', index=True)\n",
    "test_df.to_csv('X_test_feature_engineered.csv', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last submission number: 63\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Get the last submission number\n",
    "last_submission_number = int(max([int(filename.split('_')[1].split('.')[0]) for filename in os.listdir('submissions') if \"submission\" in filename]))\n",
    "print(\"Last submission number:\", last_submission_number)\n",
    "print(\"Now creating submission number:\", last_submission_number + 1)\n",
    "\n",
    "# Create the new filename\n",
    "new_filename = f'submission_{last_submission_number + 1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels/submission_64_A\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.1.0: Sun Oct  9 20:15:09 PDT 2022; root:xnu-8792.41.9~2/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   23.13 GB / 494.38 GB (4.7%)\n",
      "Train Data Rows:    34085\n",
      "Train Data Columns: 20\n",
      "Label Column: y\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 630.59471, 1165.90242)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6687.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.48 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 16 | ['estimated_diff_hours', 'absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'dew_point_2m:K', 'diffuse_rad_1h:J', ...]\n",
      "\t\t('int', [])                        :  2 | ['is_dew', 'is_rime']\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['ds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 16 | ['estimated_diff_hours', 'absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'dew_point_2m:K', 'diffuse_rad_1h:J', ...]\n",
      "\t\t('int', ['bool'])            :  2 | ['is_dew', 'is_rime']\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['ds', 'ds.year', 'ds.month', 'ds.day', 'ds.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t19 features in original data used to generate 23 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.79 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.07334604664808567, Train Rows: 31585, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.89s of the 3599.89s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for location A...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-218.6492\t = Validation score   (-mean_absolute_error)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3598.8s of the 3598.8s of remaining time.\n",
      "\t-176.0068\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3598.69s of the 3598.69s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 179.324\n",
      "[2000]\tvalid_set's l1: 171.801\n",
      "[3000]\tvalid_set's l1: 168.546\n",
      "[4000]\tvalid_set's l1: 166.446\n",
      "[5000]\tvalid_set's l1: 164.636\n",
      "[6000]\tvalid_set's l1: 163.417\n",
      "[7000]\tvalid_set's l1: 162.131\n",
      "[8000]\tvalid_set's l1: 161.328\n",
      "[9000]\tvalid_set's l1: 160.881\n",
      "[10000]\tvalid_set's l1: 160.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-160.3755\t = Validation score   (-mean_absolute_error)\n",
      "\t42.14s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3555.88s of the 3555.88s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 174.814\n",
      "[2000]\tvalid_set's l1: 170.872\n",
      "[3000]\tvalid_set's l1: 169.441\n",
      "[4000]\tvalid_set's l1: 168.934\n",
      "[5000]\tvalid_set's l1: 168.648\n",
      "[6000]\tvalid_set's l1: 168.338\n",
      "[7000]\tvalid_set's l1: 168.111\n",
      "[8000]\tvalid_set's l1: 168.002\n",
      "[9000]\tvalid_set's l1: 167.867\n",
      "[10000]\tvalid_set's l1: 167.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-167.7487\t = Validation score   (-mean_absolute_error)\n",
      "\t43.52s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3511.58s of the 3511.58s of remaining time.\n",
      "\t-189.013\t = Validation score   (-mean_absolute_error)\n",
      "\t14.79s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3496.29s of the 3496.29s of remaining time.\n",
      "\t-178.1038\t = Validation score   (-mean_absolute_error)\n",
      "\t102.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3394.15s of the 3394.15s of remaining time.\n",
      "\t-191.0823\t = Validation score   (-mean_absolute_error)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3390.56s of the 3390.56s of remaining time.\n",
      "\t-199.1758\t = Validation score   (-mean_absolute_error)\n",
      "\t46.7s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3343.79s of the 3343.79s of remaining time.\n",
      "\t-179.2972\t = Validation score   (-mean_absolute_error)\n",
      "\t49.08s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3294.19s of the 3294.19s of remaining time.\n",
      "\t-177.5656\t = Validation score   (-mean_absolute_error)\n",
      "\t236.53s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3057.62s of the 3057.62s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 166.066\n",
      "[2000]\tvalid_set's l1: 163.316\n",
      "[3000]\tvalid_set's l1: 162.862\n",
      "[4000]\tvalid_set's l1: 162.625\n",
      "[5000]\tvalid_set's l1: 162.473\n",
      "[6000]\tvalid_set's l1: 162.437\n",
      "[7000]\tvalid_set's l1: 162.409\n",
      "[8000]\tvalid_set's l1: 162.395\n",
      "[9000]\tvalid_set's l1: 162.394\n",
      "[10000]\tvalid_set's l1: 162.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-162.393\t = Validation score   (-mean_absolute_error)\n",
      "\t136.25s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 2919.26s of remaining time.\n",
      "\t-150.9047\t = Validation score   (-mean_absolute_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 680.92s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/submission_64_A\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "train_data = TabularDataset('X_train_feature_engineered.csv')\n",
    "test_data = TabularDataset('X_test_feature_engineered.csv')\n",
    "label = 'y'\n",
    "metric = 'mean_absolute_error'\n",
    "time_limit = 60*60\n",
    "\n",
    "predictors = [None, None, None]\n",
    "\n",
    "loc = \"A\"\n",
    "print(f\"Training model for location {loc}...\")\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric, path=f\"AutogluonModels/{new_filename}_{loc}\").fit(train_data[train_data[\"location\"] == loc], time_limit=time_limit)\n",
    "predictors[0] = predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels/submission_64_B\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.1.0: Sun Oct  9 20:15:09 PDT 2022; root:xnu-8792.41.9~2/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   21.88 GB / 494.38 GB (4.4%)\n",
      "Train Data Rows:    32844\n",
      "Train Data Columns: 20\n",
      "Label Column: y\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 96.82478, 193.94649)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6311.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.13 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 16 | ['estimated_diff_hours', 'absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'dew_point_2m:K', 'diffuse_rad_1h:J', ...]\n",
      "\t\t('int', [])                        :  2 | ['is_dew', 'is_rime']\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['ds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 16 | ['estimated_diff_hours', 'absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'dew_point_2m:K', 'diffuse_rad_1h:J', ...]\n",
      "\t\t('int', ['bool'])            :  2 | ['is_dew', 'is_rime']\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['ds', 'ds.year', 'ds.month', 'ds.day', 'ds.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t19 features in original data used to generate 23 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.58 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.07611740348313238, Train Rows: 30344, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.85s of the 3599.85s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for location B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-27.5392\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.78s of the 3599.78s of remaining time.\n",
      "\t-22.1104\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3599.7s of the 3599.7s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 29.4902\n",
      "[2000]\tvalid_set's l1: 27.2899\n",
      "[3000]\tvalid_set's l1: 26.1052\n",
      "[4000]\tvalid_set's l1: 25.1608\n",
      "[5000]\tvalid_set's l1: 24.5642\n",
      "[6000]\tvalid_set's l1: 24.0926\n",
      "[7000]\tvalid_set's l1: 23.75\n",
      "[8000]\tvalid_set's l1: 23.4855\n",
      "[9000]\tvalid_set's l1: 23.2792\n",
      "[10000]\tvalid_set's l1: 23.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-23.1072\t = Validation score   (-mean_absolute_error)\n",
      "\t36.7s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3562.29s of the 3562.29s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 25.2403\n",
      "[2000]\tvalid_set's l1: 24.037\n",
      "[3000]\tvalid_set's l1: 23.5399\n",
      "[4000]\tvalid_set's l1: 23.2674\n",
      "[5000]\tvalid_set's l1: 23.1749\n",
      "[6000]\tvalid_set's l1: 23.0914\n",
      "[7000]\tvalid_set's l1: 23.0135\n",
      "[8000]\tvalid_set's l1: 22.9799\n",
      "[9000]\tvalid_set's l1: 22.9526\n",
      "[10000]\tvalid_set's l1: 22.9348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-22.9348\t = Validation score   (-mean_absolute_error)\n",
      "\t40.64s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3520.8s of the 3520.79s of remaining time.\n",
      "\t-27.0486\t = Validation score   (-mean_absolute_error)\n",
      "\t15.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3504.74s of the 3504.74s of remaining time.\n",
      "\t-24.0731\t = Validation score   (-mean_absolute_error)\n",
      "\t102.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3402.62s of the 3402.62s of remaining time.\n",
      "\t-28.6908\t = Validation score   (-mean_absolute_error)\n",
      "\t2.81s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3399.23s of the 3399.23s of remaining time.\n",
      "\t-30.6298\t = Validation score   (-mean_absolute_error)\n",
      "\t43.78s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3355.39s of the 3355.39s of remaining time.\n",
      "\t-24.6042\t = Validation score   (-mean_absolute_error)\n",
      "\t31.97s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3322.86s of the 3322.86s of remaining time.\n",
      "\t-24.1336\t = Validation score   (-mean_absolute_error)\n",
      "\t467.82s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 2855.01s of the 2855.01s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 22.4058\n",
      "[2000]\tvalid_set's l1: 21.6491\n",
      "[3000]\tvalid_set's l1: 21.4479\n",
      "[4000]\tvalid_set's l1: 21.3798\n",
      "[5000]\tvalid_set's l1: 21.3509\n",
      "[6000]\tvalid_set's l1: 21.3361\n",
      "[7000]\tvalid_set's l1: 21.3288\n",
      "[8000]\tvalid_set's l1: 21.3247\n",
      "[9000]\tvalid_set's l1: 21.3233\n",
      "[10000]\tvalid_set's l1: 21.3226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-21.3226\t = Validation score   (-mean_absolute_error)\n",
      "\t135.73s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 2717.18s of remaining time.\n",
      "\t-20.1221\t = Validation score   (-mean_absolute_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 883.0s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/submission_64_B\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loc = \"B\"\n",
    "print(f\"Training model for location {loc}...\")\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric, path=f\"AutogluonModels/{new_filename}_{loc}\").fit(train_data[train_data[\"location\"] == loc], time_limit=time_limit)\n",
    "predictors[1] = predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels/submission_64_C\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.1.0: Sun Oct  9 20:15:09 PDT 2022; root:xnu-8792.41.9~2/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   20.94 GB / 494.38 GB (4.2%)\n",
      "Train Data Rows:    26095\n",
      "Train Data Columns: 20\n",
      "Label Column: y\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 77.63106, 165.81688)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6180.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.25 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 16 | ['estimated_diff_hours', 'absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'dew_point_2m:K', 'diffuse_rad_1h:J', ...]\n",
      "\t\t('int', [])                        :  2 | ['is_dew', 'is_rime']\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['ds']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 16 | ['estimated_diff_hours', 'absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'dew_point_2m:K', 'diffuse_rad_1h:J', ...]\n",
      "\t\t('int', ['bool'])            :  2 | ['is_dew', 'is_rime']\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['ds', 'ds.year', 'ds.month', 'ds.day', 'ds.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t19 features in original data used to generate 23 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.44 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.09580379383023568, Train Rows: 23595, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.88s of the 3599.88s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for location C...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-25.4907\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.82s of the 3599.82s of remaining time.\n",
      "\t-20.1032\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3599.75s of the 3599.75s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 17.6805\n",
      "[2000]\tvalid_set's l1: 17.0186\n",
      "[3000]\tvalid_set's l1: 16.7036\n",
      "[4000]\tvalid_set's l1: 16.5355\n",
      "[5000]\tvalid_set's l1: 16.4673\n",
      "[6000]\tvalid_set's l1: 16.4088\n",
      "[7000]\tvalid_set's l1: 16.3316\n",
      "[8000]\tvalid_set's l1: 16.3049\n",
      "[9000]\tvalid_set's l1: 16.2906\n",
      "[10000]\tvalid_set's l1: 16.2459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-16.2434\t = Validation score   (-mean_absolute_error)\n",
      "\t37.04s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3561.95s of the 3561.95s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 17.7442\n",
      "[2000]\tvalid_set's l1: 17.4383\n",
      "[3000]\tvalid_set's l1: 17.3238\n",
      "[4000]\tvalid_set's l1: 17.2773\n",
      "[5000]\tvalid_set's l1: 17.256\n",
      "[6000]\tvalid_set's l1: 17.2457\n",
      "[7000]\tvalid_set's l1: 17.2444\n",
      "[8000]\tvalid_set's l1: 17.2481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-17.2411\t = Validation score   (-mean_absolute_error)\n",
      "\t52.57s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3508.88s of the 3508.88s of remaining time.\n",
      "\t-19.2543\t = Validation score   (-mean_absolute_error)\n",
      "\t9.41s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3499.02s of the 3499.02s of remaining time.\n",
      "\t-17.4701\t = Validation score   (-mean_absolute_error)\n",
      "\t99.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3399.23s of the 3399.22s of remaining time.\n",
      "\t-19.4452\t = Validation score   (-mean_absolute_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3397.09s of the 3397.09s of remaining time.\n",
      "\t-19.9486\t = Validation score   (-mean_absolute_error)\n",
      "\t28.24s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3368.81s of the 3368.81s of remaining time.\n",
      "\t-18.0542\t = Validation score   (-mean_absolute_error)\n",
      "\t5.66s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3363.09s of the 3363.09s of remaining time.\n",
      "\t-16.8757\t = Validation score   (-mean_absolute_error)\n",
      "\t247.46s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3115.6s of the 3115.6s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 17.6079\n",
      "[2000]\tvalid_set's l1: 17.5059\n",
      "[3000]\tvalid_set's l1: 17.4819\n",
      "[4000]\tvalid_set's l1: 17.4752\n",
      "[5000]\tvalid_set's l1: 17.4736\n",
      "[6000]\tvalid_set's l1: 17.4721\n",
      "[7000]\tvalid_set's l1: 17.4719\n",
      "[8000]\tvalid_set's l1: 17.4717\n",
      "[9000]\tvalid_set's l1: 17.4717\n",
      "[10000]\tvalid_set's l1: 17.4717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-17.4716\t = Validation score   (-mean_absolute_error)\n",
      "\t136.44s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 2977.03s of remaining time.\n",
      "\t-15.3717\t = Validation score   (-mean_absolute_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 623.14s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/submission_64_C\")\n"
     ]
    }
   ],
   "source": [
    "loc = \"C\"\n",
    "print(f\"Training model for location {loc}...\")\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric, path=f\"AutogluonModels/{new_filename}_{loc}\").fit(train_data[train_data[\"location\"] == loc], time_limit=time_limit)\n",
    "predictors[2] = predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_ids = TabularDataset('test.csv')\n",
    "# merge test_data with test_ids\n",
    "test_data = pd.merge(test_data, test_ids, how=\"inner\", right_on=[\"time\", \"location\"], left_on=[\"ds\", \"location\"])\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: X_test_feature_engineered.csv | Columns = 20 / 20 | Rows = 4608 -> 4608\n",
      "Loaded data from: test.csv | Columns = 4 / 4 | Rows = 2160 -> 2160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>estimated_diff_hours</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>fresh_snow_1h:cm</th>\n",
       "      <th>snow_depth:cm</th>\n",
       "      <th>...</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>is_dew</th>\n",
       "      <th>is_rime</th>\n",
       "      <th>sin_sun_elevation</th>\n",
       "      <th>global_rad_1h:J</th>\n",
       "      <th>location</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-01 00:00:00</td>\n",
       "      <td>16.998889</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.286</td>\n",
       "      <td>271.700012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30210.699219</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.193978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-01 01:00:00</td>\n",
       "      <td>17.998889</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.287</td>\n",
       "      <td>271.600006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29507.500000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.158641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-01 02:00:00</td>\n",
       "      <td>18.998889</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.284</td>\n",
       "      <td>271.200012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.400002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29463.099609</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.096645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-01 03:00:00</td>\n",
       "      <td>19.998889</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.282</td>\n",
       "      <td>270.799988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33727.101562</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-05-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-01 04:00:00</td>\n",
       "      <td>20.998889</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.282</td>\n",
       "      <td>270.299988</td>\n",
       "      <td>56574.300781</td>\n",
       "      <td>19781.400391</td>\n",
       "      <td>58.599998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35927.601562</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088842</td>\n",
       "      <td>76355.701172</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-05-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2023-07-03 19:00:00</td>\n",
       "      <td>35.991389</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.196</td>\n",
       "      <td>281.600006</td>\n",
       "      <td>199266.906250</td>\n",
       "      <td>57163.699219</td>\n",
       "      <td>89.599998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41536.398438</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176776</td>\n",
       "      <td>256430.605469</td>\n",
       "      <td>C</td>\n",
       "      <td>2155</td>\n",
       "      <td>2023-07-03 19:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2023-07-03 20:00:00</td>\n",
       "      <td>36.991389</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.199</td>\n",
       "      <td>281.899994</td>\n",
       "      <td>109878.000000</td>\n",
       "      <td>39874.800781</td>\n",
       "      <td>84.400002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40136.500000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085556</td>\n",
       "      <td>149752.800781</td>\n",
       "      <td>C</td>\n",
       "      <td>2156</td>\n",
       "      <td>2023-07-03 20:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2023-07-03 21:00:00</td>\n",
       "      <td>37.991389</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.202</td>\n",
       "      <td>282.200012</td>\n",
       "      <td>44498.898438</td>\n",
       "      <td>10678.299805</td>\n",
       "      <td>68.800003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43266.101562</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012409</td>\n",
       "      <td>55177.198242</td>\n",
       "      <td>C</td>\n",
       "      <td>2157</td>\n",
       "      <td>2023-07-03 21:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2023-07-03 22:00:00</td>\n",
       "      <td>38.991389</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.206</td>\n",
       "      <td>282.600006</td>\n",
       "      <td>8968.599609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39017.898438</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.037638</td>\n",
       "      <td>8968.599609</td>\n",
       "      <td>C</td>\n",
       "      <td>2158</td>\n",
       "      <td>2023-07-03 22:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2023-07-03 23:00:00</td>\n",
       "      <td>39.991389</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.207</td>\n",
       "      <td>282.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39026.000000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.061188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>2159</td>\n",
       "      <td>2023-07-03 23:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ds  estimated_diff_hours  absolute_humidity_2m:gm3  \\\n",
       "0     2023-05-01 00:00:00             16.998889                       4.4   \n",
       "1     2023-05-01 01:00:00             17.998889                       4.3   \n",
       "2     2023-05-01 02:00:00             18.998889                       4.2   \n",
       "3     2023-05-01 03:00:00             19.998889                       4.1   \n",
       "4     2023-05-01 04:00:00             20.998889                       3.9   \n",
       "...                   ...                   ...                       ...   \n",
       "2155  2023-07-03 19:00:00             35.991389                       8.3   \n",
       "2156  2023-07-03 20:00:00             36.991389                       8.5   \n",
       "2157  2023-07-03 21:00:00             37.991389                       8.8   \n",
       "2158  2023-07-03 22:00:00             38.991389                       9.0   \n",
       "2159  2023-07-03 23:00:00             39.991389                       9.0   \n",
       "\n",
       "      air_density_2m:kgm3  dew_point_2m:K  diffuse_rad_1h:J  direct_rad_1h:J  \\\n",
       "0                   1.286      271.700012          0.000000         0.000000   \n",
       "1                   1.287      271.600006          0.000000         0.000000   \n",
       "2                   1.284      271.200012          0.000000         0.000000   \n",
       "3                   1.282      270.799988          0.000000         0.000000   \n",
       "4                   1.282      270.299988      56574.300781     19781.400391   \n",
       "...                   ...             ...               ...              ...   \n",
       "2155                1.196      281.600006     199266.906250     57163.699219   \n",
       "2156                1.199      281.899994     109878.000000     39874.800781   \n",
       "2157                1.202      282.200012      44498.898438     10678.299805   \n",
       "2158                1.206      282.600006       8968.599609         0.000000   \n",
       "2159                1.207      282.500000          0.000000         0.000000   \n",
       "\n",
       "      effective_cloud_cover:p  fresh_snow_1h:cm  snow_depth:cm  ...  \\\n",
       "0                   80.699997               0.0            0.0  ...   \n",
       "1                   64.500000               0.0            0.0  ...   \n",
       "2                   94.400002               0.0            0.0  ...   \n",
       "3                   75.000000               0.0            0.0  ...   \n",
       "4                   58.599998               0.0            0.0  ...   \n",
       "...                       ...               ...            ...  ...   \n",
       "2155                89.599998               0.0            0.0  ...   \n",
       "2156                84.400002               0.0            0.0  ...   \n",
       "2157                68.800003               0.0            0.0  ...   \n",
       "2158               100.000000               0.0            0.0  ...   \n",
       "2159               100.000000               0.0            0.0  ...   \n",
       "\n",
       "      visibility:m  wind_speed_10m:ms  is_dew  is_rime  sin_sun_elevation  \\\n",
       "0     30210.699219                4.0       0        0          -0.193978   \n",
       "1     29507.500000                3.9       0        0          -0.158641   \n",
       "2     29463.099609                3.7       0        0          -0.096645   \n",
       "3     33727.101562                3.6       0        0          -0.012217   \n",
       "4     35927.601562                3.4       0        0           0.088842   \n",
       "...            ...                ...     ...      ...                ...   \n",
       "2155  41536.398438                2.2       0        0           0.176776   \n",
       "2156  40136.500000                2.1       0        0           0.085556   \n",
       "2157  43266.101562                2.4       0        0           0.012409   \n",
       "2158  39017.898438                2.0       0        0          -0.037638   \n",
       "2159  39026.000000                1.7       0        0          -0.061188   \n",
       "\n",
       "      global_rad_1h:J  location    id                 time prediction  \n",
       "0            0.000000         A     0  2023-05-01 00:00:00          0  \n",
       "1            0.000000         A     1  2023-05-01 01:00:00          0  \n",
       "2            0.000000         A     2  2023-05-01 02:00:00          0  \n",
       "3            0.000000         A     3  2023-05-01 03:00:00          0  \n",
       "4        76355.701172         A     4  2023-05-01 04:00:00          0  \n",
       "...               ...       ...   ...                  ...        ...  \n",
       "2155    256430.605469         C  2155  2023-07-03 19:00:00          0  \n",
       "2156    149752.800781         C  2156  2023-07-03 20:00:00          0  \n",
       "2157     55177.198242         C  2157  2023-07-03 21:00:00          0  \n",
       "2158      8968.599609         C  2158  2023-07-03 22:00:00          0  \n",
       "2159         0.000000         C  2159  2023-07-03 23:00:00          0  \n",
       "\n",
       "[2160 rows x 23 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming X_test and model are already defined\n",
    "# Assuming 'time' is also a datetime64[ns] column in X_test\n",
    "\n",
    "\n",
    "test_data = TabularDataset('X_test_feature_engineered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>prediction</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-05-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-05-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2155</td>\n",
       "      <td>2023-07-03 19:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2156</td>\n",
       "      <td>2023-07-03 20:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2157</td>\n",
       "      <td>2023-07-03 21:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2158</td>\n",
       "      <td>2023-07-03 22:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2159</td>\n",
       "      <td>2023-07-03 23:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                 time  prediction location\n",
       "0        0  2023-05-01 00:00:00           0        A\n",
       "1        1  2023-05-01 01:00:00           0        A\n",
       "2        2  2023-05-01 02:00:00           0        A\n",
       "3        3  2023-05-01 03:00:00           0        A\n",
       "4        4  2023-05-01 04:00:00           0        A\n",
       "...    ...                  ...         ...      ...\n",
       "2155  2155  2023-07-03 19:00:00           0        C\n",
       "2156  2156  2023-07-03 20:00:00           0        C\n",
       "2157  2157  2023-07-03 21:00:00           0        C\n",
       "2158  2158  2023-07-03 22:00:00           0        C\n",
       "2159  2159  2023-07-03 23:00:00           0        C\n",
       "\n",
       "[2160 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>estimated_diff_hours</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>fresh_snow_1h:cm</th>\n",
       "      <th>snow_depth:cm</th>\n",
       "      <th>...</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>is_dew</th>\n",
       "      <th>is_rime</th>\n",
       "      <th>sin_sun_elevation</th>\n",
       "      <th>global_rad_1h:J</th>\n",
       "      <th>location</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>2023-05-01 00:00:00</td>\n",
       "      <td>16.998889</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.283</td>\n",
       "      <td>271.700012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31329.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.193960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>720</td>\n",
       "      <td>2023-05-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>2023-05-01 01:00:00</td>\n",
       "      <td>17.998889</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.283</td>\n",
       "      <td>271.600006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.599998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30737.800781</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.158623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>721</td>\n",
       "      <td>2023-05-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2023-05-01 02:00:00</td>\n",
       "      <td>18.998889</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.283</td>\n",
       "      <td>271.200012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.300003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29863.199219</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.096628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>722</td>\n",
       "      <td>2023-05-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>2023-05-01 03:00:00</td>\n",
       "      <td>19.998889</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.282</td>\n",
       "      <td>270.799988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.099998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33809.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>723</td>\n",
       "      <td>2023-05-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2023-05-01 04:00:00</td>\n",
       "      <td>20.998889</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.283</td>\n",
       "      <td>270.299988</td>\n",
       "      <td>56571.500000</td>\n",
       "      <td>19743.400391</td>\n",
       "      <td>58.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35603.398438</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088860</td>\n",
       "      <td>76314.900391</td>\n",
       "      <td>B</td>\n",
       "      <td>724</td>\n",
       "      <td>2023-05-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2023-07-03 19:00:00</td>\n",
       "      <td>35.991389</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.197</td>\n",
       "      <td>281.500000</td>\n",
       "      <td>206778.500000</td>\n",
       "      <td>55664.000000</td>\n",
       "      <td>88.400002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43766.398438</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177102</td>\n",
       "      <td>262442.500000</td>\n",
       "      <td>B</td>\n",
       "      <td>1435</td>\n",
       "      <td>2023-07-03 19:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2023-07-03 20:00:00</td>\n",
       "      <td>36.991389</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.200</td>\n",
       "      <td>281.700012</td>\n",
       "      <td>114277.000000</td>\n",
       "      <td>39711.699219</td>\n",
       "      <td>81.300003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43369.000000</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086008</td>\n",
       "      <td>153988.699219</td>\n",
       "      <td>B</td>\n",
       "      <td>1436</td>\n",
       "      <td>2023-07-03 20:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2023-07-03 21:00:00</td>\n",
       "      <td>37.991389</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1.203</td>\n",
       "      <td>282.100006</td>\n",
       "      <td>46271.101562</td>\n",
       "      <td>11528.700195</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44597.601562</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012967</td>\n",
       "      <td>57799.801758</td>\n",
       "      <td>B</td>\n",
       "      <td>1437</td>\n",
       "      <td>2023-07-03 21:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2023-07-03 22:00:00</td>\n",
       "      <td>38.991389</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.206</td>\n",
       "      <td>282.600006</td>\n",
       "      <td>9413.900391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41415.699219</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.037010</td>\n",
       "      <td>9413.900391</td>\n",
       "      <td>B</td>\n",
       "      <td>1438</td>\n",
       "      <td>2023-07-03 22:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2023-07-03 23:00:00</td>\n",
       "      <td>39.991389</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.207</td>\n",
       "      <td>282.700012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40004.199219</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.060508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>1439</td>\n",
       "      <td>2023-07-03 23:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ds  estimated_diff_hours  absolute_humidity_2m:gm3  \\\n",
       "720   2023-05-01 00:00:00             16.998889                       4.3   \n",
       "721   2023-05-01 01:00:00             17.998889                       4.3   \n",
       "722   2023-05-01 02:00:00             18.998889                       4.2   \n",
       "723   2023-05-01 03:00:00             19.998889                       4.1   \n",
       "724   2023-05-01 04:00:00             20.998889                       3.9   \n",
       "...                   ...                   ...                       ...   \n",
       "1435  2023-07-03 19:00:00             35.991389                       8.3   \n",
       "1436  2023-07-03 20:00:00             36.991389                       8.4   \n",
       "1437  2023-07-03 21:00:00             37.991389                       8.7   \n",
       "1438  2023-07-03 22:00:00             38.991389                       9.0   \n",
       "1439  2023-07-03 23:00:00             39.991389                       9.1   \n",
       "\n",
       "      air_density_2m:kgm3  dew_point_2m:K  diffuse_rad_1h:J  direct_rad_1h:J  \\\n",
       "720                 1.283      271.700012          0.000000         0.000000   \n",
       "721                 1.283      271.600006          0.000000         0.000000   \n",
       "722                 1.283      271.200012          0.000000         0.000000   \n",
       "723                 1.282      270.799988          0.000000         0.000000   \n",
       "724                 1.283      270.299988      56571.500000     19743.400391   \n",
       "...                   ...             ...               ...              ...   \n",
       "1435                1.197      281.500000     206778.500000     55664.000000   \n",
       "1436                1.200      281.700012     114277.000000     39711.699219   \n",
       "1437                1.203      282.100006      46271.101562     11528.700195   \n",
       "1438                1.206      282.600006       9413.900391         0.000000   \n",
       "1439                1.207      282.700012          0.000000         0.000000   \n",
       "\n",
       "      effective_cloud_cover:p  fresh_snow_1h:cm  snow_depth:cm  ...  \\\n",
       "720                 80.699997               0.0            0.0  ...   \n",
       "721                 64.599998               0.0            0.0  ...   \n",
       "722                 94.300003               0.0            0.0  ...   \n",
       "723                 75.099998               0.0            0.0  ...   \n",
       "724                 58.700001               0.0            0.0  ...   \n",
       "...                       ...               ...            ...  ...   \n",
       "1435                88.400002               0.0            0.0  ...   \n",
       "1436                81.300003               0.0            0.0  ...   \n",
       "1437                64.500000               0.0            0.0  ...   \n",
       "1438                97.000000               0.0            0.0  ...   \n",
       "1439               100.000000               0.0            0.0  ...   \n",
       "\n",
       "      visibility:m  wind_speed_10m:ms  is_dew  is_rime  sin_sun_elevation  \\\n",
       "720   31329.500000                4.0       0        0          -0.193960   \n",
       "721   30737.800781                3.9       0        0          -0.158623   \n",
       "722   29863.199219                3.7       0        0          -0.096628   \n",
       "723   33809.000000                3.6       0        0          -0.012200   \n",
       "724   35603.398438                3.4       0        0           0.088860   \n",
       "...            ...                ...     ...      ...                ...   \n",
       "1435  43766.398438                2.6       0        0           0.177102   \n",
       "1436  43369.000000                2.3       0        0           0.086008   \n",
       "1437  44597.601562                2.7       0        0           0.012967   \n",
       "1438  41415.699219                2.4       0        0          -0.037010   \n",
       "1439  40004.199219                2.1       0        0          -0.060508   \n",
       "\n",
       "      global_rad_1h:J  location    id                 time prediction  \n",
       "720          0.000000         B   720  2023-05-01 00:00:00          0  \n",
       "721          0.000000         B   721  2023-05-01 01:00:00          0  \n",
       "722          0.000000         B   722  2023-05-01 02:00:00          0  \n",
       "723          0.000000         B   723  2023-05-01 03:00:00          0  \n",
       "724      76314.900391         B   724  2023-05-01 04:00:00          0  \n",
       "...               ...       ...   ...                  ...        ...  \n",
       "1435    262442.500000         B  1435  2023-07-03 19:00:00          0  \n",
       "1436    153988.699219         B  1436  2023-07-03 20:00:00          0  \n",
       "1437     57799.801758         B  1437  2023-07-03 21:00:00          0  \n",
       "1438      9413.900391         B  1438  2023-07-03 22:00:00          0  \n",
       "1439         0.000000         B  1439  2023-07-03 23:00:00          0  \n",
       "\n",
       "[720 rows x 23 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_data[\"location\"]==\"C\").sum()\n",
    "test_data[test_data[\"location\"]==\"B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>estimated_diff_hours</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>fresh_snow_1h:cm</th>\n",
       "      <th>snow_depth:cm</th>\n",
       "      <th>...</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>is_dew</th>\n",
       "      <th>is_rime</th>\n",
       "      <th>sin_sun_elevation</th>\n",
       "      <th>global_rad_1h:J</th>\n",
       "      <th>location</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-01 00:00:00</td>\n",
       "      <td>16.998889</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.283</td>\n",
       "      <td>271.700012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31329.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.193960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>720</td>\n",
       "      <td>2023-05-01 00:00:00</td>\n",
       "      <td>2.213565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-01 01:00:00</td>\n",
       "      <td>17.998889</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.283</td>\n",
       "      <td>271.600006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.599998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30737.800781</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.158623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>721</td>\n",
       "      <td>2023-05-01 01:00:00</td>\n",
       "      <td>2.303815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-01 02:00:00</td>\n",
       "      <td>18.998889</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.283</td>\n",
       "      <td>271.200012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.300003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29863.199219</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.096628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>722</td>\n",
       "      <td>2023-05-01 02:00:00</td>\n",
       "      <td>2.387730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-01 03:00:00</td>\n",
       "      <td>19.998889</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.282</td>\n",
       "      <td>270.799988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.099998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33809.000000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>723</td>\n",
       "      <td>2023-05-01 03:00:00</td>\n",
       "      <td>6.071991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-01 04:00:00</td>\n",
       "      <td>20.998889</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.283</td>\n",
       "      <td>270.299988</td>\n",
       "      <td>56571.500000</td>\n",
       "      <td>19743.400391</td>\n",
       "      <td>58.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35603.398438</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088860</td>\n",
       "      <td>76314.900391</td>\n",
       "      <td>B</td>\n",
       "      <td>724</td>\n",
       "      <td>2023-05-01 04:00:00</td>\n",
       "      <td>46.061150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>2023-07-03 19:00:00</td>\n",
       "      <td>35.991389</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.197</td>\n",
       "      <td>281.500000</td>\n",
       "      <td>206778.500000</td>\n",
       "      <td>55664.000000</td>\n",
       "      <td>88.400002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43766.398438</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177102</td>\n",
       "      <td>262442.500000</td>\n",
       "      <td>B</td>\n",
       "      <td>1435</td>\n",
       "      <td>2023-07-03 19:00:00</td>\n",
       "      <td>31.109562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>2023-07-03 20:00:00</td>\n",
       "      <td>36.991389</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.200</td>\n",
       "      <td>281.700012</td>\n",
       "      <td>114277.000000</td>\n",
       "      <td>39711.699219</td>\n",
       "      <td>81.300003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43369.000000</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086008</td>\n",
       "      <td>153988.699219</td>\n",
       "      <td>B</td>\n",
       "      <td>1436</td>\n",
       "      <td>2023-07-03 20:00:00</td>\n",
       "      <td>14.503678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2023-07-03 21:00:00</td>\n",
       "      <td>37.991389</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1.203</td>\n",
       "      <td>282.100006</td>\n",
       "      <td>46271.101562</td>\n",
       "      <td>11528.700195</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44597.601562</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012967</td>\n",
       "      <td>57799.801758</td>\n",
       "      <td>B</td>\n",
       "      <td>1437</td>\n",
       "      <td>2023-07-03 21:00:00</td>\n",
       "      <td>11.221365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>2023-07-03 22:00:00</td>\n",
       "      <td>38.991389</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.206</td>\n",
       "      <td>282.600006</td>\n",
       "      <td>9413.900391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41415.699219</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.037010</td>\n",
       "      <td>9413.900391</td>\n",
       "      <td>B</td>\n",
       "      <td>1438</td>\n",
       "      <td>2023-07-03 22:00:00</td>\n",
       "      <td>10.734447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>2023-07-03 23:00:00</td>\n",
       "      <td>39.991389</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.207</td>\n",
       "      <td>282.700012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40004.199219</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.060508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>1439</td>\n",
       "      <td>2023-07-03 23:00:00</td>\n",
       "      <td>15.453526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ds  estimated_diff_hours  absolute_humidity_2m:gm3  \\\n",
       "0    2023-05-01 00:00:00             16.998889                       4.3   \n",
       "1    2023-05-01 01:00:00             17.998889                       4.3   \n",
       "2    2023-05-01 02:00:00             18.998889                       4.2   \n",
       "3    2023-05-01 03:00:00             19.998889                       4.1   \n",
       "4    2023-05-01 04:00:00             20.998889                       3.9   \n",
       "..                   ...                   ...                       ...   \n",
       "715  2023-07-03 19:00:00             35.991389                       8.3   \n",
       "716  2023-07-03 20:00:00             36.991389                       8.4   \n",
       "717  2023-07-03 21:00:00             37.991389                       8.7   \n",
       "718  2023-07-03 22:00:00             38.991389                       9.0   \n",
       "719  2023-07-03 23:00:00             39.991389                       9.1   \n",
       "\n",
       "     air_density_2m:kgm3  dew_point_2m:K  diffuse_rad_1h:J  direct_rad_1h:J  \\\n",
       "0                  1.283      271.700012          0.000000         0.000000   \n",
       "1                  1.283      271.600006          0.000000         0.000000   \n",
       "2                  1.283      271.200012          0.000000         0.000000   \n",
       "3                  1.282      270.799988          0.000000         0.000000   \n",
       "4                  1.283      270.299988      56571.500000     19743.400391   \n",
       "..                   ...             ...               ...              ...   \n",
       "715                1.197      281.500000     206778.500000     55664.000000   \n",
       "716                1.200      281.700012     114277.000000     39711.699219   \n",
       "717                1.203      282.100006      46271.101562     11528.700195   \n",
       "718                1.206      282.600006       9413.900391         0.000000   \n",
       "719                1.207      282.700012          0.000000         0.000000   \n",
       "\n",
       "     effective_cloud_cover:p  fresh_snow_1h:cm  snow_depth:cm  ...  \\\n",
       "0                  80.699997               0.0            0.0  ...   \n",
       "1                  64.599998               0.0            0.0  ...   \n",
       "2                  94.300003               0.0            0.0  ...   \n",
       "3                  75.099998               0.0            0.0  ...   \n",
       "4                  58.700001               0.0            0.0  ...   \n",
       "..                       ...               ...            ...  ...   \n",
       "715                88.400002               0.0            0.0  ...   \n",
       "716                81.300003               0.0            0.0  ...   \n",
       "717                64.500000               0.0            0.0  ...   \n",
       "718                97.000000               0.0            0.0  ...   \n",
       "719               100.000000               0.0            0.0  ...   \n",
       "\n",
       "     visibility:m  wind_speed_10m:ms  is_dew  is_rime  sin_sun_elevation  \\\n",
       "0    31329.500000                4.0       0        0          -0.193960   \n",
       "1    30737.800781                3.9       0        0          -0.158623   \n",
       "2    29863.199219                3.7       0        0          -0.096628   \n",
       "3    33809.000000                3.6       0        0          -0.012200   \n",
       "4    35603.398438                3.4       0        0           0.088860   \n",
       "..            ...                ...     ...      ...                ...   \n",
       "715  43766.398438                2.6       0        0           0.177102   \n",
       "716  43369.000000                2.3       0        0           0.086008   \n",
       "717  44597.601562                2.7       0        0           0.012967   \n",
       "718  41415.699219                2.4       0        0          -0.037010   \n",
       "719  40004.199219                2.1       0        0          -0.060508   \n",
       "\n",
       "     global_rad_1h:J  location    id                 time prediction  \n",
       "0           0.000000         B   720  2023-05-01 00:00:00   2.213565  \n",
       "1           0.000000         B   721  2023-05-01 01:00:00   2.303815  \n",
       "2           0.000000         B   722  2023-05-01 02:00:00   2.387730  \n",
       "3           0.000000         B   723  2023-05-01 03:00:00   6.071991  \n",
       "4       76314.900391         B   724  2023-05-01 04:00:00  46.061150  \n",
       "..               ...       ...   ...                  ...        ...  \n",
       "715    262442.500000         B  1435  2023-07-03 19:00:00  31.109562  \n",
       "716    153988.699219         B  1436  2023-07-03 20:00:00  14.503678  \n",
       "717     57799.801758         B  1437  2023-07-03 21:00:00  11.221365  \n",
       "718      9413.900391         B  1438  2023-07-03 22:00:00  10.734447  \n",
       "719         0.000000         B  1439  2023-07-03 23:00:00  15.453526  \n",
       "\n",
       "[720 rows x 23 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict, grouped by location\n",
    "predictions = []\n",
    "location_map = {\n",
    "    \"A\": 0,\n",
    "    \"B\": 1,\n",
    "    \"C\": 2\n",
    "}\n",
    "for loc, group in test_data.groupby('location'):\n",
    "    i = location_map[loc]\n",
    "    subset = test_data[test_data[\"location\"] == loc].reset_index(drop=True)\n",
    "    #print(subset)\n",
    "    pred = predictors[i].predict(subset)\n",
    "    subset[\"prediction\"] = pred\n",
    "    predictions.append(subset)\n",
    "\n",
    "\n",
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>estimated_diff_hours</th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>fresh_snow_1h:cm</th>\n",
       "      <th>snow_depth:cm</th>\n",
       "      <th>...</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>is_dew</th>\n",
       "      <th>is_rime</th>\n",
       "      <th>sin_sun_elevation</th>\n",
       "      <th>global_rad_1h:J</th>\n",
       "      <th>location</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-01 00:00:00</td>\n",
       "      <td>16.998889</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.286</td>\n",
       "      <td>271.700012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30210.699219</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.193978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-01 00:00:00</td>\n",
       "      <td>24.753420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-01 01:00:00</td>\n",
       "      <td>17.998889</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.287</td>\n",
       "      <td>271.600006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29507.500000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.158641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-01 01:00:00</td>\n",
       "      <td>18.146330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-01 02:00:00</td>\n",
       "      <td>18.998889</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.284</td>\n",
       "      <td>271.200012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.400002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29463.099609</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.096645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-01 02:00:00</td>\n",
       "      <td>25.271877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-01 03:00:00</td>\n",
       "      <td>19.998889</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.282</td>\n",
       "      <td>270.799988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33727.101562</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-05-01 03:00:00</td>\n",
       "      <td>47.294090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-01 04:00:00</td>\n",
       "      <td>20.998889</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.282</td>\n",
       "      <td>270.299988</td>\n",
       "      <td>56574.300781</td>\n",
       "      <td>19781.400391</td>\n",
       "      <td>58.599998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35927.601562</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088842</td>\n",
       "      <td>76355.701172</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-05-01 04:00:00</td>\n",
       "      <td>308.338074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2023-07-03 19:00:00</td>\n",
       "      <td>35.991389</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.196</td>\n",
       "      <td>281.600006</td>\n",
       "      <td>199266.906250</td>\n",
       "      <td>57163.699219</td>\n",
       "      <td>89.599998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41536.398438</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176776</td>\n",
       "      <td>256430.605469</td>\n",
       "      <td>C</td>\n",
       "      <td>2155</td>\n",
       "      <td>2023-07-03 19:00:00</td>\n",
       "      <td>79.219185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2023-07-03 20:00:00</td>\n",
       "      <td>36.991389</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.199</td>\n",
       "      <td>281.899994</td>\n",
       "      <td>109878.000000</td>\n",
       "      <td>39874.800781</td>\n",
       "      <td>84.400002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40136.500000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085556</td>\n",
       "      <td>149752.800781</td>\n",
       "      <td>C</td>\n",
       "      <td>2156</td>\n",
       "      <td>2023-07-03 20:00:00</td>\n",
       "      <td>45.387287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2023-07-03 21:00:00</td>\n",
       "      <td>37.991389</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.202</td>\n",
       "      <td>282.200012</td>\n",
       "      <td>44498.898438</td>\n",
       "      <td>10678.299805</td>\n",
       "      <td>68.800003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43266.101562</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012409</td>\n",
       "      <td>55177.198242</td>\n",
       "      <td>C</td>\n",
       "      <td>2157</td>\n",
       "      <td>2023-07-03 21:00:00</td>\n",
       "      <td>24.156162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2023-07-03 22:00:00</td>\n",
       "      <td>38.991389</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.206</td>\n",
       "      <td>282.600006</td>\n",
       "      <td>8968.599609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39017.898438</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.037638</td>\n",
       "      <td>8968.599609</td>\n",
       "      <td>C</td>\n",
       "      <td>2158</td>\n",
       "      <td>2023-07-03 22:00:00</td>\n",
       "      <td>12.095822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2023-07-03 23:00:00</td>\n",
       "      <td>39.991389</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.207</td>\n",
       "      <td>282.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39026.000000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.061188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>2159</td>\n",
       "      <td>2023-07-03 23:00:00</td>\n",
       "      <td>10.509235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ds  estimated_diff_hours  absolute_humidity_2m:gm3  \\\n",
       "id                                                                          \n",
       "0     2023-05-01 00:00:00             16.998889                       4.4   \n",
       "1     2023-05-01 01:00:00             17.998889                       4.3   \n",
       "2     2023-05-01 02:00:00             18.998889                       4.2   \n",
       "3     2023-05-01 03:00:00             19.998889                       4.1   \n",
       "4     2023-05-01 04:00:00             20.998889                       3.9   \n",
       "...                   ...                   ...                       ...   \n",
       "2155  2023-07-03 19:00:00             35.991389                       8.3   \n",
       "2156  2023-07-03 20:00:00             36.991389                       8.5   \n",
       "2157  2023-07-03 21:00:00             37.991389                       8.8   \n",
       "2158  2023-07-03 22:00:00             38.991389                       9.0   \n",
       "2159  2023-07-03 23:00:00             39.991389                       9.0   \n",
       "\n",
       "      air_density_2m:kgm3  dew_point_2m:K  diffuse_rad_1h:J  direct_rad_1h:J  \\\n",
       "id                                                                             \n",
       "0                   1.286      271.700012          0.000000         0.000000   \n",
       "1                   1.287      271.600006          0.000000         0.000000   \n",
       "2                   1.284      271.200012          0.000000         0.000000   \n",
       "3                   1.282      270.799988          0.000000         0.000000   \n",
       "4                   1.282      270.299988      56574.300781     19781.400391   \n",
       "...                   ...             ...               ...              ...   \n",
       "2155                1.196      281.600006     199266.906250     57163.699219   \n",
       "2156                1.199      281.899994     109878.000000     39874.800781   \n",
       "2157                1.202      282.200012      44498.898438     10678.299805   \n",
       "2158                1.206      282.600006       8968.599609         0.000000   \n",
       "2159                1.207      282.500000          0.000000         0.000000   \n",
       "\n",
       "      effective_cloud_cover:p  fresh_snow_1h:cm  snow_depth:cm  ...  \\\n",
       "id                                                              ...   \n",
       "0                   80.699997               0.0            0.0  ...   \n",
       "1                   64.500000               0.0            0.0  ...   \n",
       "2                   94.400002               0.0            0.0  ...   \n",
       "3                   75.000000               0.0            0.0  ...   \n",
       "4                   58.599998               0.0            0.0  ...   \n",
       "...                       ...               ...            ...  ...   \n",
       "2155                89.599998               0.0            0.0  ...   \n",
       "2156                84.400002               0.0            0.0  ...   \n",
       "2157                68.800003               0.0            0.0  ...   \n",
       "2158               100.000000               0.0            0.0  ...   \n",
       "2159               100.000000               0.0            0.0  ...   \n",
       "\n",
       "      visibility:m  wind_speed_10m:ms  is_dew  is_rime  sin_sun_elevation  \\\n",
       "id                                                                          \n",
       "0     30210.699219                4.0       0        0          -0.193978   \n",
       "1     29507.500000                3.9       0        0          -0.158641   \n",
       "2     29463.099609                3.7       0        0          -0.096645   \n",
       "3     33727.101562                3.6       0        0          -0.012217   \n",
       "4     35927.601562                3.4       0        0           0.088842   \n",
       "...            ...                ...     ...      ...                ...   \n",
       "2155  41536.398438                2.2       0        0           0.176776   \n",
       "2156  40136.500000                2.1       0        0           0.085556   \n",
       "2157  43266.101562                2.4       0        0           0.012409   \n",
       "2158  39017.898438                2.0       0        0          -0.037638   \n",
       "2159  39026.000000                1.7       0        0          -0.061188   \n",
       "\n",
       "      global_rad_1h:J  location    id                 time  prediction  \n",
       "id                                                                      \n",
       "0            0.000000         A     0  2023-05-01 00:00:00   24.753420  \n",
       "1            0.000000         A     1  2023-05-01 01:00:00   18.146330  \n",
       "2            0.000000         A     2  2023-05-01 02:00:00   25.271877  \n",
       "3            0.000000         A     3  2023-05-01 03:00:00   47.294090  \n",
       "4        76355.701172         A     4  2023-05-01 04:00:00  308.338074  \n",
       "...               ...       ...   ...                  ...         ...  \n",
       "2155    256430.605469         C  2155  2023-07-03 19:00:00   79.219185  \n",
       "2156    149752.800781         C  2156  2023-07-03 20:00:00   45.387287  \n",
       "2157     55177.198242         C  2157  2023-07-03 21:00:00   24.156162  \n",
       "2158      8968.599609         C  2158  2023-07-03 22:00:00   12.095822  \n",
       "2159         0.000000         C  2159  2023-07-03 23:00:00   10.509235  \n",
       "\n",
       "[2160 rows x 23 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate predictions\n",
    "predictions = pd.concat(predictions)\n",
    "predictions.index = predictions[\"id\"]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24.753420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18.146330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25.271877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>47.294090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>308.338074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2155</td>\n",
       "      <td>79.219185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2156</td>\n",
       "      <td>45.387287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2157</td>\n",
       "      <td>24.156162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2158</td>\n",
       "      <td>12.095822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2159</td>\n",
       "      <td>10.509235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  prediction\n",
       "id                    \n",
       "0        0   24.753420\n",
       "1        1   18.146330\n",
       "2        2   25.271877\n",
       "3        3   47.294090\n",
       "4        4  308.338074\n",
       "...    ...         ...\n",
       "2155  2155   79.219185\n",
       "2156  2156   45.387287\n",
       "2157  2157   24.156162\n",
       "2158  2158   12.095822\n",
       "2159  2159   10.509235\n",
       "\n",
       "[2160 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Save the submission DataFrame to submissions folder, create new name based on last submission, format is submission_<last_submission_number + 1>.csv\n",
    "\n",
    "# Save the submission\n",
    "predictions = predictions[['id', 'prediction']]\n",
    "predictions.to_csv(os.path.join('submissions', f\"{new_filename}.csv\"), index=False)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
